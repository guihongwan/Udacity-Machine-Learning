{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at the mercy of sth 任其摆布\n",
    "# i am at the mercy of this car.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised classification\n",
    "# 'Superivsed' means you have a bunch of examples where you know\n",
    "# sort of the correct answer in those examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine learning is all about learning from examples.\n",
    "#find the pattern\n",
    "#predicte\n",
    "\n",
    "#given someone's music choices and a bunch of features of that music\n",
    "#recommend a new song.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot\n",
    "# a data point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Surface /Decision boundary that help us distinguish\n",
    "# which terrain we need to go slow on and which terrain we can\n",
    "# really fast.\n",
    "\n",
    "#   linear \n",
    "#   \n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "# https://machinelearningmastery.com/naive-bayes-for-machine-learning/\n",
    "\n",
    "# Naive Bayes is a simple but surprisingly powerful algorithm for predictive modeling.\n",
    "# for classification\n",
    "# In a classification problem, our hypothesis may be the class to assign for a new data instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes' Theorem\n",
    "# Bayes' Theorem provides a way that we can calculate the probability of\n",
    "# a hypothesis(h) given our prior knowledge(d).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "\n",
    "# Naive Bayes is a classification algorithm for binary(two-class) and mult-class classification problems.\n",
    "# It is called naive Bayes because the calculation of the probalities for each hypothesis\n",
    "# are simplified to make their calculation tractable.\n",
    "# Rather than attempting to calculate P(d1,d2,d3|h), they are assumed to be\n",
    "# conditionally independent given the target value  and calculated as P(d1|h)*P(d2|h)...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representation Used by Naive Bayes Models\n",
    "# The representation for naive Bayes is probailities.\n",
    "# A list of probabilities are stored to file for a learned\n",
    "#naive Bayes mode. This includes:\n",
    "# 1. Class Probability: The probabilities of each class in the traningset.\n",
    "\n",
    "# 2. Conditional Probabilities: The conditional probabilities of each class given differnt input x.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Probability\n",
    "# For binary classification problem\n",
    "# P(class = 1) = count(class=1)/(count(class=1)+count(class=0))\n",
    "\n",
    "# for a binary classification problem with the same number of instance in each class,\n",
    "# the probability is 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Probability\n",
    "\n",
    "# The conditional probabilities are the frequency of each attribute value for a given class value divided by\n",
    "# the frequency of instances with that class value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "\n",
    "#Naive Bayes can be extended to real-valued attributes, most commonly by assuming\n",
    "# a Gaussian distribution.\n",
    "\n",
    "# This extension of naive Bayes is called Gaussian Naive Bayes.\n",
    "# Other functions can used to estimate the distribution of the data, but Gaussian(or normal distribution)\n",
    "# is the easist to work with because you only need to estimate the mean and the standard deviation from your training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best prepare data for Naive Bayes\n",
    "# - Categorical Inputs\n",
    "# - Gaussian Inputs: if the input variables are real-valued, a Gaussian distribution is assumed. \n",
    "#   this may require removing outliers(e.g. values are more than 3 or 4 standard deviations from the mean)\n",
    "# - classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[-1,-3],[-3,-2],[1,1],[3,4]])\n",
    "y_train = np.array([1,1,0,0])\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(x_train,y_train)\n",
    "pred = clf.predict([[-1,-2],[-1,2],[3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66666666666666663"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred,[1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes Rule\n",
    "\n",
    "#Prior  p(c) = 0.01 p(-c) = 0.99\n",
    "\n",
    "#test\n",
    "#P(pos|c) = 0.9   p(pos|-c) = 0.1\n",
    "#p(neg|-c) =0.9\n",
    "\n",
    "#if this person has the cancer\n",
    "# the possibility of the test gives positive\n",
    "\n",
    "# p(c, pos) = p(c).p(pos|c) = 0.009  \n",
    "# p(-c,pos) = p(-c).p(pos|-c) = 0.099\n",
    "\n",
    "#p(pos) = p(c, pos)+p(-c,pos)\n",
    "\n",
    "#posterior\n",
    "#p(c|pos) = 0.0833\n",
    "#p(-c|pos) = 0.9167"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
