{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions we might be able to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 what variables are related to subway ridership?\n",
    "# - which stations have the most riders?\n",
    "# - What are the ridership patterns overtime?\n",
    "# - how does the weather affect ridership?\n",
    "\n",
    "# 2 What patterns can I find in the weather?\n",
    "# - Is the temperature rising throught the month?\n",
    "# - How does weather vary across the city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2D data\n",
    "#python: List of lists\n",
    "#Numpy:2D array\n",
    "#Pandas: DataFrame\n",
    "# 2D array, as opposed to array of arrays:\n",
    "# More memory efficient\n",
    "#Accessing elements is a bit different a[1,3], rather than a[1][3]\n",
    "# mean(),std(),etc operate on entire array.\n",
    "\n",
    "# more :https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html#internal-memory-layout-of-an-ndarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328\n",
      "[[2328 2539]\n",
      " [6461 2691]]\n",
      "[1478 3877 3674 2328 2539]\n"
     ]
    }
   ],
   "source": [
    "print(ridership[1, 3])\n",
    "print(ridership[1:3, 3:5])\n",
    "print(ridership[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1478 3877 3676 2333 2539]\n",
      "[   0 5355 5701 4952 6410 5509  324    2 5223 5385]\n"
     ]
    }
   ],
   "source": [
    "print( ridership[0, :] + ridership[1, :] )\n",
    "print( ridership[:, 0] + ridership[:, 1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  4]\n",
      " [ 6  7  8]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "b = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "print( a + b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution by ghwan\n",
    "\n",
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to \n",
    "    find the station with the maximum riders on the first day, then \n",
    "    return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    Hint: NumPy's argmax() function might be useful:\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
    "    '''\n",
    "    \n",
    "    ridership_first_day = ridership[0,:]\n",
    "    print(ridership_first_day)\n",
    "    station_index_max_first_day = ridership_first_day.argmax()\n",
    "    print(station_index_max_first_day)\n",
    "    \n",
    "    ridership_station_max_first_day = ridership[:, station_index_max_first_day]\n",
    "    print(ridership_station_max_first_day)\n",
    "    \n",
    "    mean_for_max = ridership_station_max_first_day.mean()\n",
    "    \n",
    "    overall_mean = ridership.mean()\n",
    "    \n",
    "    return (overall_mean, mean_for_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 5 0]\n",
      "3\n",
      "[   5 2328 6461 4787 4477 4979  496   27 4174 4665]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2342.5999999999999, 3239.9000000000001)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_riders_for_max_station(ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy axis argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "[12 15 18]\n",
      "[ 6 15 24]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ])\n",
    "    \n",
    "print( a.sum() )\n",
    "print(a.sum(axis=0))\n",
    "print(a.sum(axis=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [   0,    0,    2,    5,    0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [  95,  229,  255,  496,  201],\n",
    "    [   2,    0,    1,   27,    0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_and_max_riders_per_day(ridership):\n",
    "    '''\n",
    "    Fill in this function. \n",
    "    First, for each subway station, calculate the\n",
    "    mean ridership per day. \n",
    "    Then, out of all the subway stations, \n",
    "    return the maximum and minimum of these values. \n",
    "    That is, find the maximum mean-ridership-per-day and \n",
    "    the minimum mean-ridership-per-day for any subway station.\n",
    "    '''\n",
    "    \n",
    "    mean_each_day = ridership.mean(axis = 0)\n",
    "    print(mean_each_day)\n",
    "    \n",
    "    \n",
    "    max_daily_ridership = mean_each_day.max()     # Replace this with your code\n",
    "    min_daily_ridership = mean_each_day.min()     # Replace this with your code\n",
    "    \n",
    "    return (max_daily_ridership, min_daily_ridership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1071.2  2814.9  2718.8  3239.9  1868.2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3239.9000000000001, 1071.2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_and_max_riders_per_day(ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridership.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments = np.array([\n",
    "    ['account_key', 'status', 'join_date', 'days_to_cancel', 'is_udacity'],\n",
    "    [448, 'canceled', '2014-11-10', 65, True],\n",
    "    [448, 'canceled', '2014-11-05', 5, True]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['account_key', 'status', 'join_date', 'days_to_cancel',\n",
       "        'is_udacity'],\n",
       "       ['448', 'canceled', '2014-11-10', '65', 'True'],\n",
       "       ['448', 'canceled', '2014-11-05', '5', 'True']],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the integer and boolean are converted to String\n",
    "enrollments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1ec5f6dfe9f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menrollments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "#error\n",
    "enrollments[:,3].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments = pd.DataFrame({\n",
    "    'account_key':[448, 448],\n",
    "    'status':['canceled', 'canceled'],\n",
    "    'join_date':['2014-11-10', '2014-11-05'],\n",
    "    'days_to_cancel':[65, 5],\n",
    "    'is_udacity':[True, True]\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691],\n",
    "          [1560, 3392, 3826, 4787, 2613],\n",
    "          [1608, 4802, 3932, 4477, 2705],\n",
    "          [1576, 3933, 3909, 4979, 2685],\n",
    "          [  95,  229,  255,  496,  201],\n",
    "          [   2,    0,    1,   27,    0],\n",
    "          [1438, 3785, 3589, 4174, 2215],\n",
    "          [1342, 4043, 4009, 4665, 3033]],\n",
    "    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "           '05-06-11', '05-07-11', '05-08-11', '05-09-11', '05-10-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( ridership_df.iloc[0])\n",
    "print( ridership_df.loc['05-05-11'])\n",
    "print( ridership_df['R003'])\n",
    "print( ridership_df.iloc[1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( ridership_df.iloc[1:4] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( ridership_df[['R003', 'R005']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "print(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame([[0, 1, 2], [3, 4, 5]], columns=['A', 'B', 'C'])\n",
    "print(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [0, 1, 2], 'B': [3, 4, 5]})\n",
    "print( df.sum() )\n",
    "print(  df.sum(axis=1))\n",
    "print(  df.values.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_df = pd.DataFrame(\n",
    "    data=[[   0,    0,    2,    5,    0],\n",
    "          [1478, 3877, 3674, 2328, 2539],\n",
    "          [1613, 4088, 3991, 6461, 2691],\n",
    "          [1560, 3392, 3826, 4787, 2613],\n",
    "          [1608, 4802, 3932, 4477, 2705],\n",
    "          [1576, 3933, 3909, 4979, 2685],\n",
    "          [  95,  229,  255,  496,  201],\n",
    "          [   2,    0,    1,   27,    0],\n",
    "          [1438, 3785, 3589, 4174, 2215],\n",
    "          [1342, 4043, 4009, 4665, 3033]],\n",
    "    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "           '05-06-11', '05-07-11', '05-08-11', '05-09-11', '05-10-11'],\n",
    "    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "    \n",
    "    This is the same as a previous exercise, but this time the\n",
    "    input is a Pandas DataFrame rather than a 2D NumPy array.\n",
    "    '''\n",
    "    overall_mean = ridership.values.mean() # Replace this with your code\n",
    "    \n",
    "    max_firstday = ridership.iloc[0].idxmax()#ridership_df.max(axis=1)\n",
    "    print(max_firstday)\n",
    "    data_max_station = ridership[max_firstday]\n",
    "    print(data_max_station)\n",
    "    mean_for_max = data_max_station.values.mean() # Replace this with your code\n",
    "    \n",
    "    return (overall_mean, mean_for_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_riders_for_max_station(ridership_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership = pd.DataFrame(\n",
    "    {0: [5, 5, 5],\n",
    "     1: [10, 10, 10],\n",
    "     2: [15, 15, 15],\n",
    "     3: [20, 20, 20],\n",
    "     4: [25, 25, 25]},\n",
    "    index=[0, 1, 2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_riders_for_max_station(ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_df = pd.read_csv('nyc-subway-weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_df.head() #only read some of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subway_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Correlation (Pearson's r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1 y1 <--both above mean? both below? one above and one below?    \n",
    "x2 y2 <-- ...    \n",
    "x3 y3 <-- ...    \n",
    ".   .     \n",
    ".   .    \n",
    ".   .    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson's r : ranges from -1 to +1    \n",
    "- First standardize each variable    \n",
    "- Multiply each pair of values, and     \n",
    "- take the average    \n",
    "- r = average of (x in std units) * (y in std units)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resources:    \n",
    "pearson:  http://onlinestatbook.com/2/describing_bivariate_data/pearson.html    \n",
    "statistics: http://onlinestatbook.com/2/index.html\n",
    "\n",
    "Pearson's r in NumPy:https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'nyc-subway-weather.csv'\n",
    "subway_df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIT</th>\n",
       "      <th>DATEn</th>\n",
       "      <th>TIMEn</th>\n",
       "      <th>ENTRIESn</th>\n",
       "      <th>EXITSn</th>\n",
       "      <th>ENTRIESn_hourly</th>\n",
       "      <th>EXITSn_hourly</th>\n",
       "      <th>datetime</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_week</th>\n",
       "      <th>...</th>\n",
       "      <th>pressurei</th>\n",
       "      <th>rain</th>\n",
       "      <th>tempi</th>\n",
       "      <th>wspdi</th>\n",
       "      <th>meanprecipi</th>\n",
       "      <th>meanpressurei</th>\n",
       "      <th>meantempi</th>\n",
       "      <th>meanwspdi</th>\n",
       "      <th>weather_lat</th>\n",
       "      <th>weather_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-05-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.22</td>\n",
       "      <td>0</td>\n",
       "      <td>55.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-05-01 04:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.25</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-05-01 12:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.28</td>\n",
       "      <td>0</td>\n",
       "      <td>62.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-05-01 16:00:00</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.26</td>\n",
       "      <td>0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R003</td>\n",
       "      <td>05-01-11</td>\n",
       "      <td>20:00:00</td>\n",
       "      <td>4388333</td>\n",
       "      <td>2911002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-05-01 20:00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>30.28</td>\n",
       "      <td>0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.258</td>\n",
       "      <td>55.98</td>\n",
       "      <td>7.86</td>\n",
       "      <td>40.700348</td>\n",
       "      <td>-73.887177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNIT     DATEn     TIMEn  ENTRIESn   EXITSn  ENTRIESn_hourly  \\\n",
       "0  R003  05-01-11  00:00:00   4388333  2911002              0.0   \n",
       "1  R003  05-01-11  04:00:00   4388333  2911002              0.0   \n",
       "2  R003  05-01-11  12:00:00   4388333  2911002              0.0   \n",
       "3  R003  05-01-11  16:00:00   4388333  2911002              0.0   \n",
       "4  R003  05-01-11  20:00:00   4388333  2911002              0.0   \n",
       "\n",
       "   EXITSn_hourly             datetime  hour  day_week     ...       pressurei  \\\n",
       "0            0.0  2011-05-01 00:00:00     0         6     ...           30.22   \n",
       "1            0.0  2011-05-01 04:00:00     4         6     ...           30.25   \n",
       "2            0.0  2011-05-01 12:00:00    12         6     ...           30.28   \n",
       "3            0.0  2011-05-01 16:00:00    16         6     ...           30.26   \n",
       "4            0.0  2011-05-01 20:00:00    20         6     ...           30.28   \n",
       "\n",
       "  rain  tempi  wspdi meanprecipi  meanpressurei  meantempi  meanwspdi  \\\n",
       "0    0   55.9    3.5         0.0         30.258      55.98       7.86   \n",
       "1    0   52.0    3.5         0.0         30.258      55.98       7.86   \n",
       "2    0   62.1    6.9         0.0         30.258      55.98       7.86   \n",
       "3    0   57.9   15.0         0.0         30.258      55.98       7.86   \n",
       "4    0   52.0   10.4         0.0         30.258      55.98       7.86   \n",
       "\n",
       "   weather_lat  weather_lon  \n",
       "0    40.700348   -73.887177  \n",
       "1    40.700348   -73.887177  \n",
       "2    40.700348   -73.887177  \n",
       "3    40.700348   -73.887177  \n",
       "4    40.700348   -73.887177  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subway_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y):\n",
    "    '''\n",
    "    Fill in this function to compute the correlation between the two\n",
    "    input variables. Each input is either a NumPy array or a Pandas\n",
    "    Series.\n",
    "    \n",
    "    correlation = average of (x in standard units) times (y in standard units)\n",
    "    \n",
    "    Remember to pass the argument \"ddof=0\" to the Pandas std() function!\n",
    "    '''\n",
    "    \n",
    "    mean_x = x.mean()\n",
    "    mean_y = y.mean()\n",
    "    #print(mean_x)\n",
    "    #print(mean_y)\n",
    "     \n",
    "    # By default, Pandas' std() function computes the standard deviation using Bessel's correction. \n",
    "    # Calling std(ddof=0) ensures that Bessel's correction will not be used.\n",
    "    std_x = x.std(ddof=0)\n",
    "    std_y = y.std(ddof=0)\n",
    "    #print(std_x)\n",
    "    #print(std_y)\n",
    "    \n",
    "    #standardize each variable\n",
    "    #print(x)\n",
    "    x = (x - mean_x)/std_x\n",
    "    #print(x)\n",
    "    y = (y - mean_y)/std_y\n",
    "    \n",
    "    #Multiply each pair of values, and take the average\n",
    "    return (x*y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03564851577223041\n",
      "-0.026693348321569912\n",
      "-0.22903432340833663\n",
      "0.5858954707662182\n"
     ]
    }
   ],
   "source": [
    "entries = subway_df['ENTRIESn_hourly']\n",
    "cum_entries = subway_df['ENTRIESn']\n",
    "rain = subway_df['meanprecipi']\n",
    "temp = subway_df['meantempi']\n",
    "\n",
    "print( correlation(entries, rain))\n",
    "print( correlation(entries, temp))\n",
    "print( correlation(rain, temp))\n",
    "\n",
    "print( correlation(entries, cum_entries))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.58589547],\n",
       "       [ 0.58589547,  1.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.corrcoef(entries,cum_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Axis Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of axis=0 or axis=1, you can use axis='index' or axis = 'columns'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame Vectorized Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]})\n",
    "print( df1 + df2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "print( df1 + df2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                       index=['row1', 'row2', 'row3'])\n",
    "df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                       index=['row4', 'row3', 'row2'])\n",
    "print( df1 )\n",
    "print( df2 )\n",
    "print( df1 + df2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative entries and exits for one station for a few hours.\n",
    "entries_and_exits = pd.DataFrame({\n",
    "    'ENTRIESn': [3144312, 3144335, 3144353, 3144424, 3144594,\n",
    "                 3144808, 3144895, 3144905, 3144941, 3145094],\n",
    "    'EXITSn': [1088151, 1088159, 1088177, 1088231, 1088275,\n",
    "               1088317, 1088328, 1088331, 1088420, 1088753]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_and_exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with hourly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "    #entries_and_exits_diff = entries_and_exits['ENTRIESn'] - entries_and_exits['EXITSn']\n",
    "\n",
    "    #print(entries_and_exits_diff)\n",
    "    #entries_and_exits_diff = entries_and_exits_diff.shift( 1) #2056161\n",
    "    #entries_and_exits_diff.fillna(0,inplace=True)\n",
    "    #print(entries_and_exits_diff)\n",
    "    #entries_and_exits['ENTRIESn'] = entries_and_exits['ENTRIESn'] - entries_and_exits_diff\n",
    "    #print(entries_and_exits)\n",
    "    \n",
    "    diff = entries_and_exits.shift(1)\n",
    "    #diff.fillna(0,inplace=True)\n",
    "    #print(diff)\n",
    "    \n",
    "    #print(entries_and_exits - diff)\n",
    "    return (entries_and_exits - diff)\n",
    "    #return entries_and_exits.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_hourly_entries_and_exits(entries_and_exits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Built-In Functions for DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.applymap(clean_sate)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "        'a': [1, 2, 3],\n",
    "        'b': [10, 20, 30],\n",
    "        'c': [5, 10, 15]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_one(x):\n",
    "    return x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.applymap(add_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_grade(grade):\n",
    "    if grade >= 90:\n",
    "        return 'A'\n",
    "    elif grade >= 80:\n",
    "        return 'B'\n",
    "    elif grade >= 70:\n",
    "        return 'C'\n",
    "    elif grade >= 60:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_grades(grades):\n",
    "    '''\n",
    "    Fill in this function to convert the given DataFrame of numerical\n",
    "    grades to letter grades. Return a new DataFrame with the converted\n",
    "    grade.\n",
    "    \n",
    "    The conversion rule is:\n",
    "        90-100 -> A\n",
    "        80-89  -> B\n",
    "        70-79  -> C\n",
    "        60-69  -> D\n",
    "        0-59   -> F\n",
    "    '''\n",
    "    return grades.applymap(convert_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_grades(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_grades_curve(exam_grades):\n",
    "        # Pandas has a bult-in function that will perform this calculation\n",
    "        # This will give the bottom 0% to 10% of students the grade 'F',\n",
    "        # 10% to 20% the grade 'D', and so on. You can read more about\n",
    "        # the qcut() function here:\n",
    "        # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html\n",
    "        return pd.qcut(exam_grades,\n",
    "                       [0, 0.1, 0.2, 0.5, 0.8, 1],\n",
    "                       labels=['F', 'D', 'C', 'B', 'A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # qcut() operates on a list, array, or Series. This is the\n",
    "    # result of running the function on a single column of the\n",
    "    # DataFrame.\n",
    "    print( convert_grades_curve(grades_df['exam1']))\n",
    "    \n",
    "    # qcut() does not work on DataFrames, but we can use apply()\n",
    "    # to call the function on each column separately\n",
    "    print( grades_df.apply(convert_grades_curve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the type of standard deviation calculated by default is different between numpy's .std() and pandas' .std() functions. \n",
    "# By default, numpy calculates a population standard deviation, with \"ddof = 0\". \n",
    "# On the other hand, pandas calculates a sample standard deviation, with \"ddof = 1\". \n",
    "# If we know all of the scores, then we have a population - so to standardize using pandas, we need to set \"ddof = 0\".\n",
    "\n",
    "def standardize_one_column(data):\n",
    "    mean = data.mean()\n",
    "    return (data-mean)/data.std(ddof = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    '''\n",
    "    \n",
    "    return df.apply(standardize_one_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(standardize(grades_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def practise_apply_max(data):\n",
    "    return data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def practise_apply_max_(datas):\n",
    "    return datas.apply(practise_apply_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(practise_apply_max_(grades_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': [5, 4, 3, 1, 5],\n",
    "    'b': [20, 10, 40, 50, 30],\n",
    "    'c': [25, 20, 5, 15, 10]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df.apply(np.mean) )\n",
    "print( df.apply(np.max) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_largest_inside(data):#there is a bug.\n",
    "    maxi = data.max()\n",
    "    second = 0\n",
    "    for data_point in data:\n",
    "        if data_point < maxi and data_point> second:\n",
    "            second = data_point\n",
    "    return second\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_largest(data):\n",
    "    return data.apply(second_largest_inside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(second_largest(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution by instructor\n",
    "def second_largest_column(data):\n",
    "    sorted_values = data.sort_values(ascending = False)\n",
    "    #print(sorted_values)\n",
    "    return sorted_values.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_largest_column(df['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_largest(data):\n",
    "    return data.apply(second_largest_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(second_largest(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a DataFrame to a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame + DataFrame = DataFrame\n",
    "# Series + Series = Series\n",
    "# DataFrame + Series = ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "df = pd.DataFrame({0: [10], 1: [20], 2: [30], 3: [40]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "df = pd.DataFrame({0: [10, 20, 30, 40]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "df = pd.DataFrame({\n",
    "        'a': [10, 20, 30, 40],\n",
    "        'b': [50, 60, 70, 80],\n",
    "        'c': [90, 100, 110, 120],\n",
    "        'd': [130, 140, 150, 160]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df + s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing each column again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "df = pd.DataFrame({\n",
    "        0: [10, 20, 30, 40],\n",
    "        1: [50, 60, 70, 80],\n",
    "        2: [90, 100, 110, 120],\n",
    "        3: [130, 140, 150, 160]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-fe56906a8fc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.add(s, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3090047d20df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.add(s, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.divide(s, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.divide(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The functions sub(), mul(), and div() work similarly to add()\n",
    "\n",
    "df.subtract(s, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mul(s, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddof = 0\n",
    "def standardize(df):\n",
    "    '''\n",
    "    Fill in this function to standardize each column of the given\n",
    "    DataFrame. To standardize a variable, convert each value to the\n",
    "    number of standard deviations it is above or below the mean.\n",
    "    \n",
    "    This time, try to use vectorized operations instead of apply().\n",
    "    You should get the same results as you did before.\n",
    "    '''\n",
    "    mean = df.mean()\n",
    "    std = df.std(ddof = 0)\n",
    "    print(mean)\n",
    "    print(std)\n",
    "    \n",
    "    df = df.sub(mean, axis='columns')\n",
    "    df = df.div(std, axis='columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_rows(df):\n",
    "    '''\n",
    "    Optional: Fill in this function to standardize each row of the given\n",
    "    DataFrame. Again, try not to use apply().\n",
    "    \n",
    "    This one is more challenging than standardizing each column!\n",
    "    '''\n",
    "    mean = df.mean(axis='columns')\n",
    "    std = df.std(ddof = 0,axis='columns')\n",
    "    print(mean)\n",
    "    print(std)\n",
    "    \n",
    "    \n",
    "    df = df.sub(mean, axis='index')\n",
    "    df = df.div(std, axis='index')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.mean(axis='columns'))\n",
    "print(df.std(ddof=0,axis='columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize_rows(grades_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {0: [95, 85, 75, 65, 55], 1: [94, 84, 74, 64, 54]},\n",
    "    index=[0, 1, 2, 3, 4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = example_df.groupby('even')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = example_df.groupby(['even', 'above_three'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = example_df.groupby('even')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.sum()['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data['value'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'nyc-subway-weather.csv'\n",
    "subway_df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write code here to group the subway data by a variable of your choice, then\n",
    "### either print out the mean ridership within each group or create a plot.\n",
    "grouped_subway = subway_df.groupby('day_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_subway.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_by_day = grouped_subway['ENTRIESn_hourly'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import seaborn as sns\n",
    "ridership_by_day.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_by_day = grouped_subway['rain'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import seaborn as sns\n",
    "rain_by_day.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_subway = subway_df.groupby('TIMEn')\n",
    "ridership_by_time = grouped_subway['ENTRIESn_hourly'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import seaborn as sns\n",
    "ridership_by_time.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using groupby() to Calculate Hourly Entries and Exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In the quiz where you calculated hourly entries and exits, you did so for a single set of cumulative entries. \n",
    "\n",
    "However, in the original data, there was a separate set of numbers for each station.\n",
    "\n",
    "Thus, to correctly calculate the hourly entries and exits, \n",
    "it was necessary to group by station and day, then calculate the hourly entries and exits within each day.\n",
    "\n",
    "Write a function to do that. \n",
    "You should use the apply() function to call the function you wrote previously. \n",
    "You should also make sure you restrict your grouped data to just the entries and exits columns, \n",
    "since your function may cause an error if it is called on non-numerical data types.\n",
    "\n",
    "If you would like to learn more about using groupby() in Pandas, this page contains more details.http://pandas.pydata.org/pandas-docs/stable/groupby.html\n",
    "\n",
    "Note: You will not be able to reproduce the ENTRIESn_hourly and EXITSn_hourly columns in the full dataset \n",
    "using this method. When creating the dataset, we did extra processing to remove erroneous values.\n",
    "\n",
    "\n",
    "To clarify the structure of the data, the original data recorded the cumulative number of entries on each station at four-hour intervals. \n",
    "For the quiz, you just need to look at the differences between consecutive measurements on each station: \n",
    "by computing \"hourly entries\", \n",
    "we just mean recording the number of new tallies between each recording period as a contrast to \"cumulative entries\".\n",
    "\n",
    "'''\n",
    "\n",
    "subway_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(xs):\n",
    "    return (xs - xs.mean()) / xs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = example_df.groupby('even')\n",
    "print(grouped_data.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data['value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data['value'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data['value'].apply(standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_largest(xs):\n",
    "    sorted_xs = xs.sort_values(inplace=False, ascending=False)\n",
    "    return sorted_xs.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = example_df.groupby('even')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data['value'].apply(second_largest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_df = pd.DataFrame({\n",
    "    'UNIT': ['R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051', 'R079', 'R051'],\n",
    "    'TIMEn': ['00:00:00', '02:00:00', '04:00:00', '06:00:00', '08:00:00', '10:00:00', '12:00:00', '14:00:00', '16:00:00'],\n",
    "    'ENTRIESn': [3144312, 8936644, 3144335, 8936658, 3144353, 8936687, 3144424, 8936819, 3144594],\n",
    "    'EXITSn': [1088151, 13755385,  1088159, 13755393,  1088177, 13755598, 1088231, 13756191,  1088275]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_entry_and_exit(entries_and_exits):\n",
    "    diff = entries_and_exits.shift(1)\n",
    "    return (entries_and_exits - diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_entries_and_exits(entries_and_exits):\n",
    "    grouped_data = entries_and_exits.groupby('UNIT')\n",
    "    return grouped_data['ENTRIESn','EXITSn'].apply(get_hourly_entry_and_exit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hourly_entries_and_exits(ridership_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_and_exits = pd.DataFrame(\n",
    "    {'ENTRIESn': [10, 40, 60, 65, 85],\n",
    "     'EXITSn': [0, 10, 20, 60, 60],\n",
    "     'UNIT': ['R001', 'R001', 'R001', 'R001', 'R001']},\n",
    "    index=[0, 1, 2, 3, 4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hourly_entries_and_exits(entries_and_exits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how = 'left'\n",
    "#how = 'inner\n",
    "#merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_and_exits = pd.DataFrame(\n",
    "    {'ENTRIESn': [10, 40, 60, 65, 85],\n",
    "     'EXITSn': [0, 10, 20, 60, 60],\n",
    "     'UNIT': ['R001', 'R001', 'R001', 'R001', 'R001']},\n",
    "    index=[0, 1, 2, 3, 4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = entries_and_exits.groupby('UNIT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = grouped_data['ENTRIESn'].apply(get_hourly_entry_and_exit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exits = grouped_data['EXITSn'].apply(get_hourly_entry_and_exit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = pd.DataFrame(entries)\n",
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exits = pd.DataFrame(exits)\n",
    "exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries.merge(exits, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments1 = pd.DataFrame({\n",
    "    'account_key':[447, 448, 448],\n",
    "    'days_to_cancel':[100,65, 5],\n",
    "    'status':['current', 'current', 'canceled'],\n",
    "    'join_date':['2014-11-07','2014-11-10', '2014-11-05']\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments2 = pd.DataFrame({\n",
    "    'account_key':[448, 448, 449],\n",
    "    'days_to_cancel':[65, 5, 9],\n",
    "    'is_udacity':[True, False, False]\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments2.merge(enrollments1, on=['account_key'])#product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments2.merge(enrollments1, on=['account_key','days_to_cancel'])#product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments2.merge(enrollments1, on='account_key', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments2.merge(enrollments1, on='account_key', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments2.merge(enrollments1, on='account_key', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments2.merge(enrollments1, on='account_key', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollments2.merge(enrollments1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_df = pd.DataFrame({\n",
    "    'UNIT': ['R003', 'R003', 'R003', 'R003', 'R003', 'R004', 'R004', 'R004',\n",
    "             'R004', 'R004'],\n",
    "    'DATEn': ['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "              '05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'ENTRIESn': [ 4388333,  4388348,  4389885,  4391507,  4393043, 14656120,\n",
    "                 14656174, 14660126, 14664247, 14668301],\n",
    "    'EXITSn': [ 2911002,  2911036,  2912127,  2913223,  2914284, 14451774,\n",
    "               14451851, 14454734, 14457780, 14460818],\n",
    "    'latitude': [ 40.689945,  40.689945,  40.689945,  40.689945,  40.689945,\n",
    "                  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.872564, -73.872564, -73.872564, -73.872564,\n",
    "                  -73.867135, -73.867135, -73.867135, -73.867135, -73.867135]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame({\n",
    "    'DATEn': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dfs(subway_df, weather_df):\n",
    "    '''\n",
    "    Fill in this function to take 2 DataFrames, one with subway data and one with weather data, and \n",
    "    return a single dataframe with one row for each date, hour, and location. \n",
    "    Only include times and locations that have both subway data and weather data available.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    return subway_df.merge(weather_df, on = ['DATEn','hour','latitude','longitude'], how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combine_dfs(subway_df, weather_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.DataFrame({\n",
    "    'date': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'hour': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_weather_df = subway_df.merge(weather_df, \n",
    "                left_on = ['DATEn','hour','latitude','longitude'], \n",
    "                right_on = ['date','hour','latitude','longitude'] ,\n",
    "                how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting with DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_weather_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more complicated plots you will usually want to use matplotlib directly\n",
    "# https://matplotlib.org/api/pyplot_api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_even = example_df.groupby('even').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_even['even'] # Causes an error. 'even' is no longer a column in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_even = example_df.groupby('even', as_index=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_even['even'] # Now 'even' is still a column in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'nyc-subway-weather.csv'\n",
    "subway_df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subway_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a plot of your choice here showing something interesting about the subway data.\n",
    "## Matplotlib documentation here: http://matplotlib.org/api/pyplot_api.html\n",
    "## Once you've got something you're happy with, share it on the forums!\n",
    "grouped_data = subway_df.groupby('UNIT',as_index=False).first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_data['UNIT','ENTRIESn'].plot()#scatter  grouped_data['ENTRIESn','EXITSn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a0f7302a8f56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UNIT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrouped_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ENTRIESn_hourly'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.scatter(grouped_data['UNIT'],grouped_data['ENTRIESn_hourly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subway_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a9cb6c0df83a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrouped_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubway_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tempi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tempi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrouped_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ENTRIESn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subway_df' is not defined"
     ]
    }
   ],
   "source": [
    "grouped_data = subway_df.groupby('tempi',as_index=False).first()\n",
    "plt.scatter(grouped_data['tempi'],grouped_data['ENTRIESn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'subway_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a58ac756c16f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrouped_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubway_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rain'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mgrouped_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'subway_df' is not defined"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import seaborn as sns\n",
    "\n",
    "grouped_data = subway_df.groupby('rain')\n",
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_location = subway_df.groupby(['latitude','longitude'], as_index = False ).mean()\n",
    "data_by_location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_entries = data_by_location['EXITSn_hourly']/data_by_location['EXITSn_hourly'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.scatter(data_by_location['latitude'], data_by_location['longitude'],s= scaled_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histograms of subway ridership on both days with rain and days without rain\n",
    "data_by_rain = subway_df.groupby(['rain','DATEn'], as_index = False ).mean()\n",
    "data_by_rain.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.scatter(data_by_rain['DATEn'], data_by_rain['ENTRIESn'],c = data_by_rain['rain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rain = data_by_rain.loc[data_by_rain['rain'] ==0,['DATEn','ENTRIESn_hourly']]\n",
    "#print(data_by_rain.head())\n",
    "print(data_rain.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_no_rain = data_by_rain.loc[data_by_rain['rain'] ==1,['DATEn','ENTRIESn_hourly']]\n",
    "data_no_rain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.hist(data_rain['ENTRIESn_hourly'])\n",
    "plt.hist(data_no_rain['ENTRIESn_hourly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.scatter(data_rain['DATEn'],data_rain['ENTRIESn_hourly'])\n",
    "plt.scatter(data_no_rain['DATEn'],data_no_rain['ENTRIESn_hourly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three-Dimensional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D data in NumPy\n",
    "#NumPy arrays can have arbitrarily many dimensions. \n",
    "a = np.array([\n",
    "    [['A1A','A2A','A3A'],['A1B','A2B','A3B']],\n",
    "    [['B1A','B2A','B3A'],['B1B','B2B','B3B']],\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D data in Pandas\n",
    "#Panda has a data structure called a Panel, which is similar to a DataFrame or a Seriews, but for 3D data.\n",
    "# http://pandas.pydata.org/pandas-docs/stable/dsintro.html#panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more links\n",
    "#Red pandas playing in the snow  https://www.youtube.com/watch?v=DSehQsYU9h4\n",
    "#Giant panda puts baby panda to bed http://www.dailymail.co.uk/video/news/video-1085584/TOO-CUTE-Giant-Panda-puts-Baby-Panda-bed-Taipei-Zoo.html\n",
    "#Pandas playing on a slide  https://www.youtube.com/watch?v=sGF6bOi1NfA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
