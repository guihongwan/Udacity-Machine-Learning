{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision trees allow us to ask multiple linear questions,\n",
    "# one after another\n",
    "# 'decision_trees.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "x = [[0,0],[1,1]]\n",
    "y = [0,1]\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(x,y)\n",
    "clf.predict([[2,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "#min_samples_split = 2 # if there are more than 1 samples \n",
    "#in the leaf, DecisionTreeClassifier can continue to split\n",
    "#if it is small, it may be overfitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data impurity and Entropy\n",
    "\n",
    "#Entropy: controls how a DT decides where to split the data\n",
    "#definition: measure of impurity in a bunch of examples\n",
    "#example: SPEED LIMIT\n",
    "\n",
    "# entropy = ∑ - Pi log(Pi)\n",
    "# Pi: fraction of examples in class i\n",
    "# here, the log base is 2, since there are 2 classes,\n",
    "# then entropy will have a maximal value of 1.\n",
    "\n",
    "# all examples are same class = > entropy =0\n",
    "# examples are evenly split between classes = > entropy = 1\n",
    "\n",
    "#lower entropy points toward more organized data, and\n",
    "# a decision tree uses that as a way how classify events.\n",
    "\n",
    "\n",
    "# entropy = ∑ - Pi log(Pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information Gain\n",
    "\n",
    "#information gain = entropy(parent) - [weighted average] entropy(children)\n",
    "#Decision tree algorithm: maximize information gain\n",
    "\n",
    "#- 1/3*math.log(1/3,2)-2/3*math.log(2/3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caveat\n",
    "# splitting criterion \n",
    "# a tunable parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias-Variance Dilemma\n",
    "#Bias: A high bias machine learning algorithm is one that \n",
    "# practically ignores the data.\n",
    "# It has almost no capacity to learn anything.\n",
    "# e.g. a bias car would be one that I can train, and \n",
    "# no matter which way I train it, it doesn't do anything differently.\n",
    "\n",
    "# Variance: the other extreme and make a car that is extremely perceptive to data\n",
    "# and it can only replicate stuff it's seen before.\n",
    "# it will react very poorly in situation it hasn't seen before.\n",
    "\n",
    "#bias-variance trad-off: an algorithm that has some authority to generalize\n",
    "# but is still very open to listen to the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limitations\n",
    "#1. they are prone to overfitting, especially if you have data that has a lot of features.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
